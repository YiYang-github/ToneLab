{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from math import radians, sin, cos, sqrt, atan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangyi/anaconda3/envs/ToneLab/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 82 unique phonemes\n",
      "Filtered phonemes: ['t', 'o', 'h', 'ɑ', 'l', 's', 'k', 'ŋ', 'x', 'ɕ', 'i', 'e', 'p', 'm', 'ʂ', 'u', 'Ǿ', 'n', 'ȵ', 'ʯ', 'ʐ', 'f', 'ɚ', 'æ', 'ʅ', 'ɿ', 'ə', '̃', 'a', 'r', 'd', 'ɡ', 'b', 'z', 'y', 'ʑ', 'ɪ', 'ʔ', 'ɛ', 'ɔ', 'ɤ', 'ᴀ', 'v', 'ɦ', 'ᴇ', 'ɐ', 'ɵ', 'ɥ', 'ʃ', 'ʮ', 'ʊ', 'ɾ', 'ɒ', 'ɘ', 'ã', 'ẽ', 'ʒ', 'ɣ', 'ɞ', 'j', 'ᴂ', 'õ', 'ʉ', 'ɨ', 'ɻ', 'ʌ', 'ɯ', 'ø', 'ı', '∅', 'œ', 'ɬ', 'θ', 'Ø', 'ʦ', 'ʨ', 'g', 'ʏ', 'ɜ', 'ɸ', 'c', 'ʷ']\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tonelab.tone2vec\n",
    "importlib.reload(tonelab.tone2vec)\n",
    "from tonelab.tone2vec import loading, parse_phonemes, tone_feats, plot\n",
    "\n",
    "dataset_path, dataset_info = 'tests/examples/dataset.csv', 'tests/examples/info.csv' \n",
    "dataset, labels = loading(dataset_path), loading(dataset_info, column_name='areas')\n",
    "initial_list, final_list, all_list,  tone_list = parse_phonemes(dataset)\n",
    "feats = tone_feats(tone_list)\n",
    "plot(feats, labels, 'PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import umap\n",
    "import math\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from typing import List\n",
    "from torch import optim\n",
    "from random import sample\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.manifold import TSNE, MDS, Isomap\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "def train_and_evaluate(model, train_loader, valid_loader, optimizer, device, num_epochs, save_dir, unique_transcription, print_interval):\n",
    "    \"\"\"\n",
    "    Train the model on the training set and select the best performing model on the validation set.\n",
    "\n",
    "    Args:\n",
    "    - model: The neural network model to train.\n",
    "    - train_loader: DataLoader for the training dataset.\n",
    "    - valid_loader: DataLoader for the validation dataset.\n",
    "    - optimizer: Optimizer for updating the model parameters.\n",
    "    - device: Device to run the training on (e.g., 'cpu' or 'cuda').\n",
    "    - num_epochs: Number of training epochs.\n",
    "    - save_dir: Directory to save the best model and training logs.\n",
    "    - unique_transcription: Tensor containing unique transcriptions for evaluation.\n",
    "    - print_interval: int, interval for printing the logs.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    log_file_path = os.path.join(save_dir, 'training_log.txt')\n",
    "    unique_transcription = unique_transcription.to(device)\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "    with open(log_file_path, 'w') as log_file:\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "        best_valid_accuracy = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss_accum = 0\n",
    "\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                values = model(batch_X)\n",
    "                loss = criterion(values, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss_accum += loss.item()\n",
    "\n",
    "            scheduler.step()\n",
    "            log_file.write(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss_accum / len(train_loader):.4f}\\n')\n",
    "\n",
    "            model.eval()\n",
    "            train_correct, valid_correct = 0, 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                    values = model(batch_X)\n",
    "                    train_correct += eval_metric(values, batch_y, unique_transcription, metric_type='acc')\n",
    "\n",
    "                for batch_X, batch_y in valid_loader:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                    values = model(batch_X)\n",
    "                    valid_correct += eval_metric(values, batch_y, unique_transcription, metric_type='acc')\n",
    "\n",
    "            valid_accuracy = valid_correct / len(valid_loader.dataset)\n",
    "            train_accuracy = train_correct / len(train_loader.dataset)\n",
    "\n",
    "            log_file.write(f'Epoch [{epoch+1}/{num_epochs}], Train Accuracy: {train_accuracy:.4f}, Valid Accuracy: {valid_accuracy:.4f}\\n')\n",
    "\n",
    "            if (epoch + 1) % print_interval == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Train Accuracy: {train_accuracy:.4f}, Valid Accuracy: {valid_accuracy:.4f}\\n')\n",
    "\n",
    "            if valid_accuracy > best_valid_accuracy:\n",
    "                best_valid_accuracy = valid_accuracy\n",
    "                best_model_path = os.path.join(save_dir, 'best_model.pth')\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                log_file.write(f\"Saved Best Model at Epoch {epoch+1} with Valid Accuracy: {best_valid_accuracy:.4f}\\n\")\n",
    "\n",
    "            log_file.flush()\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "def testing(model, test_feat, test_label, unique_transcription, checkpoint_dir, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set.\n",
    "\n",
    "    Args:\n",
    "    - model: The neural network model to train.\n",
    "    \"\"\"\n",
    "\n",
    "    best_model_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
    "    model_state_dict = torch.load(best_model_path, map_location=device)\n",
    "    model.load_state_dict(model_state_dict)\n",
    "\n",
    "    unique_transcription = unique_transcription.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        feats, labels = test_feat.to(device), test_label.to(device)\n",
    "        values = model(feats)\n",
    "\n",
    "        accuracy = eval_metric(values, labels, unique_transcription, metric_type='acc')\n",
    "        loss   = eval_metric(values, labels, unique_transcription, metric_type='mae')\n",
    "\n",
    "        return accuracy/test_feat.shape[0], loss/test_feat.shape[0]\n",
    "\n",
    "\n",
    "def eval_metric(values, batch_y, unique_transcription, metric_type='acc'):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy or MAE of the predictions.\n",
    "\n",
    "    Args:\n",
    "    - values: torch.tensor of shape (batch_size, 3), the predicted values.\n",
    "    - batch_y: torch.tensor of shape (batch_size, 3), the true labels.\n",
    "    - unique_transcription: torch.tensor of shape (n, 3), the tensor containing unique transcriptions.\n",
    "    - metric_type: str, the type of metric to calculate ('acc' for accuracy, 'mae' for mean absolute error).\n",
    "\n",
    "    Returns:\n",
    "    - int or float, the calculated metric (number of correct predictions for accuracy, total MAE for mean absolute error).\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for index in range(batch_y.size(0)):\n",
    "        signal = batch_y[index]\n",
    "        value = values[index]\n",
    "        pred_seq = match_transcription(value, unique_transcription)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if torch.sum(torch.abs(pred_seq - signal)) < 1e-2:\n",
    "                correct += 1\n",
    "            total_loss += torch.sum(torch.abs(pred_seq - signal))\n",
    "\n",
    "    if metric_type == 'acc':\n",
    "        return correct\n",
    "    elif metric_type == 'mae':\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ToneLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
